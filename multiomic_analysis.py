#!/usr/bin/env python3
"""
Multiomic Analysis

This script provides downstream analysis for integrated multi-omic data generated by the Multi-Omic Integration Pipeline.

Features:
1. Statistical summaries of each omic layer across samples
2. Plot generation (e.g., heatmaps, scatter plots)
3. Clustering and correlation analysis
4. Protein-expression centered summarization (protein_only, no_protein, single_entry per gene)

Usage:
    python multiomic_analysis.py \
        --input_dir <directory of integrated CSVs> \
        --manifest <manifest file> \
        --out_dir <output directory> \
        [--step stats|plots|cluster|protein_only|no_protein|single_entry|all]

Arguments:
    --input_dir  Directory containing per-sample integrated CSV files
    --manifest   Tab-delimited manifest file listing sample IDs in the first column
    --out_dir    Directory to write analysis outputs
    --step       Analysis step to run: stats, plots, cluster, protein_only (selects for genes with protein expression), no_protein (selects for genes without protein expression), single_entry (compresses each gene information into a single row selecting for highest E value and averaging beta values), or all (default: all)
"""

import argparse
import logging
import os
from pathlib import Path
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from scipy.cluster.hierarchy import linkage, dendrogram

# Configure logging
target_logger = logging.getLogger()
target_logger.setLevel(logging.INFO)


def parse_args():
    parser = argparse.ArgumentParser(description="Multi-Omic Analysis Pipeline")
    parser.add_argument('--input_dir', required=True,
                        help='Directory of per-sample integrated CSV files')
    parser.add_argument('--manifest', required=True,
                        help='Manifest file listing sample IDs')
    parser.add_argument('--out_dir', required=True,
                        help='Directory for analysis results')
    parser.add_argument('--step', choices=['stats','plots','cluster','protein_only','no_protein','single_entry','all'], default='all',
                        help='Analysis step to run (default: all)')
    return parser.parse_args()


def load_data(input_dir, manifest):
    """Load integrated CSV files into a dict of DataFrames."""
    sample_ids = pd.read_table(manifest, header=None).iloc[:,0].astype(str)
    data = {}
    for sid in sample_ids:
        fp = Path(input_dir) / f"{sid}.csv"
        if not fp.exists():
            logging.warning(f"Missing file: {fp}")
            continue
        data[sid] = pd.read_csv(fp)
    return data


def compute_statistics(data, out_dir):
    """Compute and save basic summary statistics for each omic layer."""
    stats_list = []
    for sid, df in data.items():
        desc = df.describe().transpose()
        desc['sample_id'] = sid
        stats_list.append(desc)
    stats_df = pd.concat(stats_list)
    out_file = Path(out_dir) / 'omic_statistics.csv'
    stats_df.to_csv(out_file)
    logging.info(f"Saved statistics to {out_file}")


def generate_plots(data, out_dir):
    """Generate heatmap of correlation matrix across samples."""
    combined = pd.concat(data.values(), keys=data.keys())
    corr = combined.corr()
    fig, ax = plt.subplots()
    cax = ax.matshow(corr)
    fig.colorbar(cax)
    ax.set_xticks(range(len(corr.columns)))
    ax.set_xticklabels(corr.columns, rotation=90)
    ax.set_yticks(range(len(corr.index)))
    ax.set_yticklabels(corr.index)
    plt.tight_layout()
    plot_file = Path(out_dir) / 'correlation_heatmap.png'
    plt.savefig(plot_file)
    plt.close(fig)
    logging.info(f"Saved correlation heatmap to {plot_file}")


def clustering_analysis(data, out_dir):
    """Perform hierarchical clustering across samples based on integrated profiles."""
    combined = pd.concat(data.values(), keys=data.keys())
    Z = linkage(combined.fillna(0).transpose(), method='ward')
    fig, ax = plt.subplots()
    dendrogram(Z, labels=combined.columns)
    plt.tight_layout()
    plot_file = Path(out_dir) / 'dendrogram.png'
    plt.savefig(plot_file)
    plt.close(fig)
    logging.info(f"Saved dendrogram to {plot_file}")


def protein_only(data, out_dir):
    """Averages beta for ENSGene, selects protein expression, drops duplicates."""
    tmp = Path(out_dir) / 'tmp_prot'
    tmp.mkdir(exist_ok=True)
    sample_ids = data.keys()
    for sid in sample_ids:
        df = data[sid]
        df = df[df['NP'].notna() & df['beta'].notna()]
        parts = []
        for gene, subdf in df.groupby('ENSGene'):
            avg = subdf['beta'].mean()
            subdf = subdf.drop_duplicates(subset=['ENSGene','ST','END','#CHROM','NP','SEQ'])
            subdf['beta avg'] = avg
            parts.append(subdf)
        result = pd.concat(parts)
        result.insert(0,'Prot-exp',1)
        result.to_csv(tmp/f"{sid}.csv", index=False)
    shutil.move(str(tmp), str(Path(out_dir)/'prot_only'))
    logging.info("prot_only step complete")


def no_protein(data, out_dir):
    """Averages beta for ENSGene, selects mutations without protein expression, drops duplicates."""
    tmp = Path(out_dir) / 'tmp_noprot'
    tmp.mkdir(exist_ok=True)
    for sid, df in data.items():
        df = df[df['beta'].notna()]
        df['NP'] = df['NP'].fillna('m')
        df = df[df['NP'].str.contains('m')]
        parts = []
        for gene, subdf in df.groupby('ENSGene'):
            avg = subdf['beta'].mean()
            sub = subdf.drop_duplicates(subset=['ENSGene','ST','END','#CHROM'])
            sub['beta avg'] = avg
            parts.append(sub)
        result = pd.concat(parts)
        result.insert(0,'Prot-exp',0)
        result.to_csv(tmp/f"{sid}.csv", index=False)
    shutil.move(str(tmp), str(Path(out_dir)/'no_prot'))
    logging.info("no_prot step complete")


def single_entry(data, out_dir):
    """Select one entry per mutation and combine prot and noprot."""
    tmp = Path(out_dir) / 'tmp_trim'
    tmp.mkdir(exist_ok=True)
    prot = pd.read_csv(Path(out_dir)/'prot_only'/f"{sid}.csv")
    nop = pd.read_csv(Path(out_dir)/'no_prot'/f"{sid}.csv")
    result = pd.concat([prot, nop])
    # drop duplicates by key
    result = result.sort_values('E-value').drop_duplicates(subset=['ENSG','ST','END','CHR'])
    result.to_csv(tmp/f"{sid}.csv", index=False)
    shutil.move(str(tmp), str(Path(out_dir)/'trim'))
    logging.info("trim step complete")


def main():
    args = parse_args()
    out = Path(args.out_dir)
    out.mkdir(parents=True, exist_ok=True)

    data = load_data(args.input_dir, args.manifest)

    if args.step in ['stats', 'all']:
        compute_statistics(data, out)
    if args.step in ['plots', 'all']:
        generate_plots(data, out)
    if args.step in ['cluster', 'all']:
        clustering_analysis(data, out)
    if args.step in ['protein-only', 'all']:
        protein_only_only(data, out)
    if args.step in ['no-protein', 'all']:
        no_protein(data, out)
    if args.step in ['single_entry', 'all']:
        single_entry(data, out)

if __name__ == '__main__':
    main()
